{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6LTPW7LBjXX",
        "outputId": "77e0038f-3191-4079-b60d-08925236dd4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting illustration2vec\n",
            "  Downloading illustration2vec-0.1.0.tar.gz (8.4 kB)\n",
            "Collecting chainer>=4.1.0\n",
            "  Downloading chainer-7.8.1.tar.gz (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=6.7 in /usr/local/lib/python3.7/dist-packages (from illustration2vec) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from illustration2vec) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from illustration2vec) (7.1.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from illustration2vec) (0.18.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from chainer>=4.1.0->illustration2vec) (57.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from chainer>=4.1.0->illustration2vec) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from chainer>=4.1.0->illustration2vec) (3.8.0)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from chainer>=4.1.0->illustration2vec) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from chainer>=4.1.0->illustration2vec) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.0->illustration2vec) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.0->illustration2vec) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.0->illustration2vec) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.0->illustration2vec) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.0->illustration2vec) (2021.11.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.0->illustration2vec) (1.7.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.0->illustration2vec) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.0->illustration2vec) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.0->illustration2vec) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.0->illustration2vec) (3.0.9)\n",
            "Building wheels for collected packages: illustration2vec, chainer\n",
            "  Building wheel for illustration2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for illustration2vec: filename=illustration2vec-0.1.0-py3-none-any.whl size=9643 sha256=f3746ac83f7958651bc30e6e8d319ae4ba644406fa4f97999f8f2cad503d2b8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/78/84/d165cacd48da017722d9d3541890fc9d200b19c6ab7ae37a30\n",
            "  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chainer: filename=chainer-7.8.1-py3-none-any.whl size=967740 sha256=e9ae186719d21ff9528f4822dea4564018db314cec443f9b307b541eb72b0254\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/6a/6f/fd563166cc597e5206e375ea074ea836e5db5dd58421215672\n",
            "Successfully built illustration2vec chainer\n",
            "Installing collected packages: chainer, illustration2vec\n",
            "Successfully installed chainer-7.8.1 illustration2vec-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install illustration2vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rezoo/illustration2vec.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObOuGm_nx4AN",
        "outputId": "d0a68867-299c-433f-b42d-372f5a877939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'illustration2vec'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Total 145 (delta 0), reused 0 (delta 0), pack-reused 145\u001b[K\n",
            "Receiving objects: 100% (145/145), 15.49 MiB | 28.17 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh illustration2vec/get_models.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep3cxzWpjJAZ",
        "outputId": "264e7358-9726-477d-c8fd-79c6347e7593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pre-trained models...\n",
            "--2022-09-30 14:10:17--  https://github.com/rezoo/illustration2vec/releases/download/v2.0.0/tag_list.json.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/43010401/5769c876-8d89-11e7-9cc4-77ce2b4e5ad7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220930T141017Z&X-Amz-Expires=300&X-Amz-Signature=a82f9723d8c75f44731bc61d7765e9eeccc45ece6934331c15266429080bef39&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=43010401&response-content-disposition=attachment%3B%20filename%3Dtag_list.json.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-30 14:10:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/43010401/5769c876-8d89-11e7-9cc4-77ce2b4e5ad7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220930T141017Z&X-Amz-Expires=300&X-Amz-Signature=a82f9723d8c75f44731bc61d7765e9eeccc45ece6934331c15266429080bef39&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=43010401&response-content-disposition=attachment%3B%20filename%3Dtag_list.json.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10420 (10K) [application/octet-stream]\n",
            "Saving to: ‘tag_list.json.gz’\n",
            "\n",
            "\rtag_list.json.gz      0%[                    ]       0  --.-KB/s               \rtag_list.json.gz    100%[===================>]  10.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-30 14:10:17 (68.0 MB/s) - ‘tag_list.json.gz’ saved [10420/10420]\n",
            "\n",
            "--2022-09-30 14:10:17--  https://github.com/rezoo/illustration2vec/releases/download/v2.0.0/illust2vec_tag.prototxt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/43010401/51ff84f2-8d89-11e7-9703-acf4d3392948?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220930T141017Z&X-Amz-Expires=300&X-Amz-Signature=b8f9a2fd6275ab1c8c90c23318ab9ef1a152f414def7ab718e4062b609d3ddea&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=43010401&response-content-disposition=attachment%3B%20filename%3Dillust2vec_tag.prototxt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-30 14:10:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/43010401/51ff84f2-8d89-11e7-9703-acf4d3392948?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220930T141017Z&X-Amz-Expires=300&X-Amz-Signature=b8f9a2fd6275ab1c8c90c23318ab9ef1a152f414def7ab718e4062b609d3ddea&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=43010401&response-content-disposition=attachment%3B%20filename%3Dillust2vec_tag.prototxt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4045 (4.0K) [application/octet-stream]\n",
            "Saving to: ‘illust2vec_tag.prototxt’\n",
            "\n",
            "illust2vec_tag.prot 100%[===================>]   3.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-30 14:10:17 (43.4 MB/s) - ‘illust2vec_tag.prototxt’ saved [4045/4045]\n",
            "\n",
            "--2022-09-30 14:10:17--  https://github.com/rezoo/illustration2vec/releases/download/v2.0.0/illust2vec_tag_ver200.caffemodel\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/43010401/01685cda-8d89-11e7-9df0-6bbb289a6ec5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220930T140950Z&X-Amz-Expires=300&X-Amz-Signature=02edf8c787314cb446c12601767dfbfe4c0052e7b3ae47188195f5941033deb1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=43010401&response-content-disposition=attachment%3B%20filename%3Dillust2vec_tag_ver200.caffemodel&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-30 14:10:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/43010401/01685cda-8d89-11e7-9df0-6bbb289a6ec5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220930T140950Z&X-Amz-Expires=300&X-Amz-Signature=02edf8c787314cb446c12601767dfbfe4c0052e7b3ae47188195f5941033deb1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=43010401&response-content-disposition=attachment%3B%20filename%3Dillust2vec_tag_ver200.caffemodel&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 188008685 (179M) [application/octet-stream]\n",
            "Saving to: ‘illust2vec_tag_ver200.caffemodel’\n",
            "\n",
            "illust2vec_tag_ver2 100%[===================>] 179.30M   178MB/s    in 1.0s    \n",
            "\n",
            "2022-09-30 14:10:18 (178 MB/s) - ‘illust2vec_tag_ver200.caffemodel’ saved [188008685/188008685]\n",
            "\n",
            "--2022-09-30 14:10:18--  https://github.com/rezoo/illustration2vec/releases/download/v2.0.0/illust2vec_ver200.caffemodel\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/43010401/c5460918-8d89-11e7-9df1-10eeacaaebcb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220930T140953Z&X-Amz-Expires=300&X-Amz-Signature=114cf68201848f6fca7f064b27334e6dc060ddd23bf99ca53efb484620d47088&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=43010401&response-content-disposition=attachment%3B%20filename%3Dillust2vec_ver200.caffemodel&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-30 14:10:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/43010401/c5460918-8d89-11e7-9df1-10eeacaaebcb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220930T140953Z&X-Amz-Expires=300&X-Amz-Signature=114cf68201848f6fca7f064b27334e6dc060ddd23bf99ca53efb484620d47088&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=43010401&response-content-disposition=attachment%3B%20filename%3Dillust2vec_ver200.caffemodel&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978590066 (933M) [application/octet-stream]\n",
            "Saving to: ‘illust2vec_ver200.caffemodel’\n",
            "\n",
            "illust2vec_ver200.c 100%[===================>] 933.26M   171MB/s    in 5.3s    \n",
            "\n",
            "2022-09-30 14:10:24 (175 MB/s) - ‘illust2vec_ver200.caffemodel’ saved [978590066/978590066]\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import i2v\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import gc"
      ],
      "metadata": {
        "id": "aPxhN12lienW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "illust2vec = i2v.make_i2v_with_chainer(\n",
        "    \"illustration2vec/illust2vec_tag_ver200.caffemodel\", \"illustration2vec/tag_list.json\")"
      ],
      "metadata": {
        "id": "8AX8YwhB8YUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EqualLR:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def compute_weight(self, module):\n",
        "        weight = getattr(module, self.name + '_orig')\n",
        "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
        "\n",
        "        return weight * math.sqrt(2 / fan_in)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply(module, name):\n",
        "        fn = EqualLR(name)\n",
        "\n",
        "        weight = getattr(module, name)\n",
        "        del module._parameters[name]\n",
        "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
        "        module.register_forward_pre_hook(fn)\n",
        "\n",
        "        return fn\n",
        "\n",
        "    def __call__(self, module, input):\n",
        "        weight = self.compute_weight(module)\n",
        "        setattr(module, self.name, weight)\n",
        "\n",
        "\n",
        "def equal_lr(module, name='weight'):\n",
        "    EqualLR.apply(module, name)\n",
        "\n",
        "    return module"
      ],
      "metadata": {
        "id": "MAjoGvsn8jKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EqualLinear(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        linear = nn.Linear(in_dim, out_dim)\n",
        "        linear.weight.data.normal_()\n",
        "        linear.bias.data.zero_()\n",
        "\n",
        "        self.linear = equal_lr(linear)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "cTfvVsyWGxas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EqualConv2d(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        conv = nn.Conv2d(*args, **kwargs)\n",
        "        conv.weight.data.normal_()\n",
        "        conv.bias.data.zero_()\n",
        "        self.conv = equal_lr(conv)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.conv(input)"
      ],
      "metadata": {
        "id": "-UtGRxA8G8So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConstantInput(nn.Module):\n",
        "    def __init__(self, channel, size=4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input = nn.Parameter(torch.randn(1, channel, size, size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch = x.shape[0]\n",
        "        out = self.input.repeat(batch, 1, 1, 1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "B_b2mA1DG9Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoiseInjection(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super().__init__()\n",
        "\n",
        "        self.weight = nn.Parameter(torch.zeros(1, channel, 1, 1))\n",
        "\n",
        "    def forward(self, image, noise):\n",
        "        return image + self.weight * noise"
      ],
      "metadata": {
        "id": "I-dFXO_5HAYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveInstanceNorm(nn.Module):\n",
        "    def __init__(self, in_channel, style_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm = nn.InstanceNorm2d(in_channel)\n",
        "        self.style = nn.Linear(style_dim, in_channel * 2)\n",
        "        self.style.bias.data[:in_channel] = 1\n",
        "        self.style.bias.data[in_channel:] = 0\n",
        "\n",
        "    def forward(self, input, style):\n",
        "        style = self.style(style).unsqueeze(2).unsqueeze(3)\n",
        "        gamma, beta = style.chunk(2, 1)\n",
        "\n",
        "        out = self.norm(input)\n",
        "        out = gamma * out + beta\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "o7U9-s5UHKpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BlurFunctionBackward(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, grad_output, kernel, kernel_flip):\n",
        "        ctx.save_for_backward(kernel, kernel_flip)\n",
        "\n",
        "        grad_input = F.conv2d(\n",
        "            grad_output, kernel_flip, padding=1, groups=grad_output.shape[1]\n",
        "        )\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, gradgrad_output):\n",
        "        kernel, kernel_flip = ctx.saved_tensors\n",
        "\n",
        "        grad_input = F.conv2d(\n",
        "            gradgrad_output, kernel, padding=1, groups=gradgrad_output.shape[1]\n",
        "        )\n",
        "\n",
        "        return grad_input, None, None\n",
        "\n",
        "\n",
        "class BlurFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, kernel, kernel_flip):\n",
        "        ctx.save_for_backward(kernel, kernel_flip)\n",
        "\n",
        "        output = F.conv2d(input, kernel, padding=1, groups=input.shape[1])\n",
        "\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        kernel, kernel_flip = ctx.saved_tensors\n",
        "\n",
        "        grad_input = BlurFunctionBackward.apply(grad_output, kernel, kernel_flip)\n",
        "\n",
        "        return grad_input, None, None\n",
        "\n",
        "\n",
        "blur = BlurFunction.apply\n",
        "\n",
        "\n",
        "class Blur(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super().__init__()\n",
        "\n",
        "        weight = torch.tensor([[1, 2, 1], [2, 4, 2], [1, 2, 1]], dtype=torch.float32)\n",
        "        weight = weight.view(1, 1, 3, 3)\n",
        "        weight = weight / weight.sum()\n",
        "        weight_flip = torch.flip(weight, [2, 3])\n",
        "\n",
        "        self.register_buffer('weight', weight.repeat(channel, 1, 1, 1))\n",
        "        self.register_buffer('weight_flip', weight_flip.repeat(channel, 1, 1, 1))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return blur(input, self.weight, self.weight_flip)"
      ],
      "metadata": {
        "id": "KJMsagjAHOep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StyledConvBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel,\n",
        "        out_channel,\n",
        "        kernel_size=3,\n",
        "        padding=1,\n",
        "        style_dim=512,\n",
        "        initial=False,\n",
        "        upsample=False,\n",
        "        fused=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if initial:\n",
        "            self.conv1 = ConstantInput(in_channel)\n",
        "\n",
        "        else:\n",
        "            if upsample:\n",
        "              \n",
        "                self.conv1 = nn.Sequential(\n",
        "                    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                    EqualConv2d(\n",
        "                        in_channel, out_channel, kernel_size, padding=padding\n",
        "                    ),\n",
        "                    Blur(out_channel),\n",
        "                )\n",
        "            else:\n",
        "                self.conv1 = EqualConv2d(\n",
        "                    in_channel, out_channel, kernel_size, padding=padding\n",
        "                )\n",
        "\n",
        "        self.noise1 = NoiseInjection(out_channel)\n",
        "        self.adain1 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
        "        self.lrelu1 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.conv2 = EqualConv2d(out_channel, out_channel, kernel_size, padding=padding)\n",
        "        self.noise2 = NoiseInjection(out_channel)\n",
        "        self.adain2 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
        "        self.lrelu2 = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x, style, noise):\n",
        "        out = self.conv1(x)\n",
        "        out = self.noise1(out, noise)\n",
        "        out = self.lrelu1(out)\n",
        "        out = self.adain1(out, style)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.noise2(out, noise)\n",
        "        out = self.lrelu2(out)\n",
        "        out = self.adain2(out, style)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "yQrYIH7pHlYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=512, n_linear=5):\n",
        "        super(Generator, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(n_linear):\n",
        "            layers.append(EqualLinear(z_dim, z_dim))\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "        self.style = nn.Sequential(*layers)\n",
        "        self.progression = nn.ModuleList(\n",
        "            [\n",
        "              StyledConvBlock(512, 512, 3, 1, initial=True),\n",
        "              StyledConvBlock(512, 256, 3, 1, upsample=True),\n",
        "              StyledConvBlock(256, 128, 3, 1, upsample=True),\n",
        "              StyledConvBlock(128, 64, 3, 1, upsample=True),\n",
        "              StyledConvBlock(64, 32, 3, 1, upsample=True),\n",
        "            ]\n",
        "        )\n",
        "        self.to_rgb = EqualConv2d(32, 3, 1)\n",
        "\n",
        "    def forward(self, x, noise=None, step=0):\n",
        "        batch = x.size(0)\n",
        "        if noise is None:\n",
        "            noise = []\n",
        "            for i in range(step + 1):\n",
        "                size = 4 * 2 ** i\n",
        "                noise.append(torch.randn(batch, 1, size, size, device=x[0].device))\n",
        "        x = x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + 1e-8)\n",
        "        styles = self.style(x)\n",
        "        out = noise[0]\n",
        "        for i, conv in enumerate(self.progression):\n",
        "            out = self.progression[i](out, styles, noise[i])\n",
        "        return self.to_rgb(out)"
      ],
      "metadata": {
        "id": "YzAnq8_N8WoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1onMMJ7lqjStn0l8xetgRqc1IpQQa9u4t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac1TOO0h8CNU",
        "outputId": "0ff5364f-94f0-49d4-cedd-1f0ff0249d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1onMMJ7lqjStn0l8xetgRqc1IpQQa9u4t\n",
            "To: /content/Generator.pth\n",
            "100% 56.4M/56.4M [00:00<00:00, 72.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = torch.load(\"Generator.pth\", map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "7LQDPZSf8LD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 10000\n",
        "batch_size = 50\n",
        "n_iter = n_samples // batch_size\n",
        "df = {\"hair\":[], \"hair_length\":[], \"eyes\": [], \"smile\":[], \"blush\": []}\n",
        "for i in range(n_iter):\n",
        "  z = torch.randn(50, 512)\n",
        "  step = int(math.log(64, 2)) - 2\n",
        "  out = G(z, step=step)\n",
        "\n",
        "  if os.path.exists(\"vectors.csv\"):\n",
        "    with open(\"vectors.csv\", \"ab\") as f:\n",
        "      np.savetxt(f, z.detach().numpy(), delimiter=\",\")\n",
        "  else:\n",
        "    np.savetxt(\"vectors.csv\", z.detach().numpy(), delimiter=\",\")\n",
        "  \n",
        "  val_min, _ = out.reshape(out.shape[0], -1).min(axis=1)\n",
        "  val_min = val_min.reshape(-1, 1, 1, 1)\n",
        "  val_max, _ = out.reshape(out.shape[0], -1).max(axis=1)\n",
        "  val_max = val_max.reshape(-1, 1, 1, 1)\n",
        "\n",
        "  transform = T.ToPILImage()\n",
        "  imgs = (out-val_min)/(val_max-val_min)\n",
        "  imgs = [transform(img) for img in imgs]\n",
        "\n",
        "  res = illust2vec.estimate_plausible_tags(imgs, threshold=0.3)\n",
        "\n",
        "  for i, attr_dict in enumerate(res):\n",
        "    hair_values = list(filter(lambda x: \"hair\" in x[0] and \n",
        "                            \"short\" not in x[0] and \"long\" not in x[0], attr_dict['general']))\n",
        "    hair_len_values = list(filter(lambda x: \"short\" in x[0] or \"long\" in x[0], \n",
        "                            attr_dict['general']))\n",
        "    eye_values = list(filter(lambda x: \"eyes\" in x[0], attr_dict['general']))\n",
        "    if len(hair_values) > 0:\n",
        "      df[\"hair\"].append(hair_values[0][0].split()[0])\n",
        "    else:\n",
        "      df[\"hair\"].append(np.nan)\n",
        "    if len(hair_len_values) > 0:\n",
        "      df[\"hair_length\"].append(hair_len_values[0][0].split()[0])\n",
        "    else:\n",
        "      df[\"hair_length\"].append(np.nan)\n",
        "    if len(eye_values) > 0:\n",
        "      df[\"eyes\"].append(eye_values[0][0].split()[0])\n",
        "    else:\n",
        "      df[\"eyes\"].append(np.nan)\n",
        "    if len(list(filter(lambda x: x[0]=='smile', attr_dict['general']))) >0:\n",
        "      df[\"smile\"].append(True)\n",
        "    else:\n",
        "      df[\"smile\"].append(False)\n",
        "    if len(list(filter(lambda x: x[0]=='blush', attr_dict['general']))) >0:\n",
        "      df[\"blush\"].append(True)\n",
        "    else:\n",
        "      df[\"blush\"].append(False)\n",
        "    gc.collect()\n",
        "df = pd.DataFrame(df)"
      ],
      "metadata": {
        "id": "kGB1oaELCdPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TELBO5nnLWOT",
        "outputId": "876acab3-4814-4f7c-c876-7effe24387bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        hair hair_length   eyes  smile  blush\n",
              "0        NaN         NaN    NaN  False  False\n",
              "1        NaN         NaN   blue  False  False\n",
              "2        NaN         NaN  green  False  False\n",
              "3        NaN         NaN   blue  False  False\n",
              "4       pink         NaN   blue  False  False\n",
              "...      ...         ...    ...    ...    ...\n",
              "4995     NaN         NaN    NaN  False  False\n",
              "4996  blonde         NaN   blue  False  False\n",
              "4997     NaN         NaN    NaN  False  False\n",
              "4998     NaN         NaN    NaN  False  False\n",
              "4999     NaN         NaN    NaN  False  False\n",
              "\n",
              "[5000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0c266ea-e841-442d-a4a1-eb7dd8be84a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hair</th>\n",
              "      <th>hair_length</th>\n",
              "      <th>eyes</th>\n",
              "      <th>smile</th>\n",
              "      <th>blush</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blue</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>green</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blue</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pink</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blue</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>blonde</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blue</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0c266ea-e841-442d-a4a1-eb7dd8be84a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0c266ea-e841-442d-a4a1-eb7dd8be84a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0c266ea-e841-442d-a4a1-eb7dd8be84a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"hair\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp7HBPKWDuzV",
        "outputId": "56f94bdb-340e-4de2-b0ef-800c974b3d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "blonde    2350\n",
              "pink       598\n",
              "purple     211\n",
              "red         50\n",
              "green       30\n",
              "blue        22\n",
              "brown        9\n",
              "black        5\n",
              "silver       2\n",
              "Name: hair, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"hair_length\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ckZY2VmIQ2_",
        "outputId": "c97216bb-77d7-4b19-8c6e-e00e4698e2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "short    646\n",
              "long     130\n",
              "Name: hair_length, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"eyes\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yia8IB6ZCe7z",
        "outputId": "45f7824a-0d60-4b90-9fde-7e561bdc9bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "blue      4880\n",
              "green      533\n",
              "red         24\n",
              "purple      16\n",
              "aqua         2\n",
              "Name: eyes, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"smile\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvQpkAIcGN3d",
        "outputId": "52d98469-7dca-44ed-b80b-43cc3cc1571a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    9998\n",
              "True        2\n",
              "Name: smile, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"blush\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1QNoJq8I-70",
        "outputId": "b8de81b2-e914-4993-924c-811471049cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    10000\n",
              "Name: blush, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"attributes.csv\", index=False)"
      ],
      "metadata": {
        "id": "UzH2rqL2QYDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7QR9Ih7Qk9I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}